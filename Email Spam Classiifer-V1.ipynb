{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data   = pd.read_csv('./train_data.csv').astype(str)\n",
    "train_labels = pd.read_csv('./train_labels.csv').astype(str)\n",
    "test_data    = pd.read_csv ('./test_data.csv').astype(str)\n",
    "test_labels  = pd.read_csv ('./test_labels.csv').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nels final announcement final announcement north eastern linguistic society th annual meet october s nels conference host university delaware newark de complete information include information lodge transportation conference program web nels website http sun ling udel edu nel further information please contact one follow member nels committee our conference email address nel udel edu kenneth allen hyde univ delaware dept linguistic kenny udel edu \n"
     ]
    }
   ],
   "source": [
    "text = train_data.training_data[0]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "words = set(text_to_word_sequence(text))\n",
    "vocab_size = len(words)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44, 11, 13, 11, 13, 54, 40, 8, 20, 24, 10, 28, 59, 23, 44, 46, 24, 4, 21, 42, 49, 39, 13, 29, 13, 12, 21, 46, 42, 24, 44, 15, 46, 55, 49, 46, 24, 52, 47, 13, 5, 45, 60, 42, 8, 44, 7, 49, 46, 36, 46, 52, 46, 24, 39, 56, 35, 41, 21, 53, 8, 48, 46, 24]\n"
     ]
    }
   ],
   "source": [
    "result = one_hot(text, round(vocab_size*1.3))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_one_hot(data, length):\n",
    "    result = []\n",
    "    final = []\n",
    "    for i in range(length):\n",
    "        text = (data.training_data[i])\n",
    "        words = set(text_to_word_sequence(text))\n",
    "        #print(words)\n",
    "        vocab_size = len(words)\n",
    "        result = one_hot(text, round(vocab_size*1.3))\n",
    "        final.append(result)\n",
    "               \n",
    "    return final  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlist = tokenize_one_hot(train_data, len(train_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
